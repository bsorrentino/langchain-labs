{
    "cells": [
        {
            "language": "typescript",
            "source": [
                "import dotenv from 'dotenv'\n\nconst result = dotenv.config({ path: '../.env' })"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "import  OpenAI from \"openai\";\nimport { pull } from \"langchain/hub\";\nimport { PromptTemplate } from \"@langchain/core/prompts\";\nconst openai = new OpenAI();\n\n// const image_url = \"https://res.cloudinary.com/practicaldev/image/fetch/s--B-s5n03y--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bm8v47dhrqxagsd615q1.png\"\n// const image_url =  \"https://res.cloudinary.com/practicaldev/image/fetch/s--XN5WM5-1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/x21bjaiyzhbtz2p1t0t4.png\"\n\nconst prompt = await pull<PromptTemplate>('bsorrentino/image_to_plantuml')\n\nasync function converImageToDiagram( image_url_or_data:string ) {\n  const response = await openai.chat.completions.create({\n    model: \"gpt-4-vision-preview\",\n    max_tokens: 2000,\n    temperature: 0.5,\n    messages: [\n      {\n        role: \"user\",\n        content: [\n          { type: \"text\", text: await prompt.format({}) },\n          {\n            type: \"image_url\",\n            image_url: {\n              \"url\": image_url_or_data,\n            },\n          },\n        ],\n      },\n    ],\n  });\n  const content = response.choices[0].message.content;\n\n\n  return content\n}\n\n"
            ],
            "outputs": []
        },
        {
            "language": "typescript",
            "source": [
                "declare  function converImageToDiagram( image_url_or_data:string ):Promise<string>\n\n// import {createInterface} from 'node:readline/promises'\n// import { stdin as input, stdout as output } from 'node:process'\n// const rl = createInterface( {input, output} )\n// const filePath = await rl.question( 'image file')\n\nimport * as fs from 'node:fs/promises'\nimport path from 'node:path'\n\nconst filePath = \"/Users/bsorrentino/WORKSPACES/GITHUB.me/bsorrentino/bsorrentino#gh-pages/_draft/Datastax-langchain-architecture-design-guide/img_p3_1.png\"\nconst fileData = await fs.readFile( path.join( filePath) )\n// Convert the buffer to a base64 string\n\nconst base64Image = Buffer.from(fileData).toString('base64')\n\nconst imageData = `data:image/png;base64,${base64Image}`\n\nconst plantUml = await converImageToDiagram( imageData )\n\nconsole.log( plantUml )"
            ],
            "outputs": []
        }
    ]
}